<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-beta.45">
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html, body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme');
			const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
			if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
				document.documentElement.classList.toggle('dark', true);
			}
    </script>
    <link rel="icon" href="/icon/111.ico"><title>Flink基本篇 | shAilene</title><meta name="description" content="just be simple.">
    <link rel="modulepreload" href="/study/assets/app.5448d7f4.js"><link rel="modulepreload" href="/study/assets/flink基本篇.html.503c3e3d.js"><link rel="modulepreload" href="/study/assets/flink基本篇.html.c485bb3b.js"><link rel="prefetch" href="/study/assets/index.html.f8001632.js"><link rel="prefetch" href="/study/assets/index.html.cba74984.js"><link rel="prefetch" href="/study/assets/index.html.1eb4a63a.js"><link rel="prefetch" href="/study/assets/index.html.b64818c8.js"><link rel="prefetch" href="/study/assets/gin.html.bd56431d.js"><link rel="prefetch" href="/study/assets/golang.html.e71cf675.js"><link rel="prefetch" href="/study/assets/gorm.html.c8d169e9.js"><link rel="prefetch" href="/study/assets/Javaweb.html.b53682a8.js"><link rel="prefetch" href="/study/assets/ES.html.09e87f33.js"><link rel="prefetch" href="/study/assets/一些知识点的记录.html.e10426ac.js"><link rel="prefetch" href="/study/assets/Java笔记.html.357aea7e.js"><link rel="prefetch" href="/study/assets/dubbo.html.b9ef8e69.js"><link rel="prefetch" href="/study/assets/springcloud（上）.html.4b0f9893.js"><link rel="prefetch" href="/study/assets/springcloud（下）.html.af615b92.js"><link rel="prefetch" href="/study/assets/zookeeper.html.5a7a51e7.js"><link rel="prefetch" href="/study/assets/《并发编程的艺术》笔记.html.7563b673.js"><link rel="prefetch" href="/study/assets/并发编程.html.968a602f.js"><link rel="prefetch" href="/study/assets/尚硅谷_宋红康_JDBC.html.3889cfa5.js"><link rel="prefetch" href="/study/assets/redis.html.02940b08.js"><link rel="prefetch" href="/study/assets/Mybatis.html.e9bad8b9.js"><link rel="prefetch" href="/study/assets/spring.html.22bbb209.js"><link rel="prefetch" href="/study/assets/springboot.html.f6108dcb.js"><link rel="prefetch" href="/study/assets/springboot.html.ce1aeed3.js"><link rel="prefetch" href="/study/assets/springMVC.html.bdfe5403.js"><link rel="prefetch" href="/study/assets/kafka.html.af0deff6.js"><link rel="prefetch" href="/study/assets/RabbitMQ.html.13dff712.js"><link rel="prefetch" href="/study/assets/操作系统.html.359cabbb.js"><link rel="prefetch" href="/study/assets/flink基本篇2.html.db4c63c8.js"><link rel="prefetch" href="/study/assets/MySQL数据库笔记-第一部分.html.968bc543.js"><link rel="prefetch" href="/study/assets/MySQL数据库笔记-第二部分.html.25d9f940.js"><link rel="prefetch" href="/study/assets/404.html.93146c89.js"><link rel="prefetch" href="/study/assets/index.html.b309cb97.js"><link rel="prefetch" href="/study/assets/index.html.0b28fec9.js"><link rel="prefetch" href="/study/assets/index.html.75a723cf.js"><link rel="prefetch" href="/study/assets/index.html.6b9174f1.js"><link rel="prefetch" href="/study/assets/gin.html.09094b4a.js"><link rel="prefetch" href="/study/assets/golang.html.1b08179c.js"><link rel="prefetch" href="/study/assets/gorm.html.f94ab3ea.js"><link rel="prefetch" href="/study/assets/Javaweb.html.3e73a9e2.js"><link rel="prefetch" href="/study/assets/ES.html.7e58d761.js"><link rel="prefetch" href="/study/assets/一些知识点的记录.html.ba20c95c.js"><link rel="prefetch" href="/study/assets/Java笔记.html.d59825c7.js"><link rel="prefetch" href="/study/assets/dubbo.html.bdc16e11.js"><link rel="prefetch" href="/study/assets/springcloud（上）.html.830e8d2b.js"><link rel="prefetch" href="/study/assets/springcloud（下）.html.9ce93944.js"><link rel="prefetch" href="/study/assets/zookeeper.html.32cd88b2.js"><link rel="prefetch" href="/study/assets/《并发编程的艺术》笔记.html.636a9c55.js"><link rel="prefetch" href="/study/assets/并发编程.html.b15f2c9c.js"><link rel="prefetch" href="/study/assets/尚硅谷_宋红康_JDBC.html.38f58441.js"><link rel="prefetch" href="/study/assets/redis.html.13a5ecb9.js"><link rel="prefetch" href="/study/assets/Mybatis.html.9ebf0dd1.js"><link rel="prefetch" href="/study/assets/spring.html.38a0d121.js"><link rel="prefetch" href="/study/assets/springboot.html.af00f3f8.js"><link rel="prefetch" href="/study/assets/springboot.html.904a1379.js"><link rel="prefetch" href="/study/assets/springMVC.html.1429a9dd.js"><link rel="prefetch" href="/study/assets/kafka.html.58836353.js"><link rel="prefetch" href="/study/assets/RabbitMQ.html.c601276a.js"><link rel="prefetch" href="/study/assets/操作系统.html.6c435cc6.js"><link rel="prefetch" href="/study/assets/flink基本篇2.html.7ea0e08c.js"><link rel="prefetch" href="/study/assets/MySQL数据库笔记-第一部分.html.15139052.js"><link rel="prefetch" href="/study/assets/MySQL数据库笔记-第二部分.html.bb537533.js"><link rel="prefetch" href="/study/assets/404.html.4fefb49d.js"><link rel="prefetch" href="/study/assets/404.535aafe9.js"><link rel="prefetch" href="/study/assets/Layout.48708715.js">
    <link rel="stylesheet" href="/study/assets/style.2bba04cf.css">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a href="/study/" class=""><img class="logo" src="/study/images/leo.jpg" alt="shAilene"><span class="site-name can-hide">shAilene</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide"><!--[--><div class="navbar-item"><a href="/study/java/" class="" aria-label="Java"><!--[--><!--]--> Java <!--[--><!--]--></a></div><div class="navbar-item"><a href="/study/go/" class="" aria-label="Go"><!--[--><!--]--> Go <!--[--><!--]--></a></div><div class="navbar-item"><a href="/study/python/" class="" aria-label="Python"><!--[--><!--]--> Python <!--[--><!--]--></a></div><div class="navbar-item"><a href="/study/mw/" class="router-link-active" aria-label="中间件"><!--[--><!--]--> 中间件 <!--[--><!--]--></a></div><!--]--></nav><!--[--><!--]--><button class="toggle-dark-button" title="toggle dark mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items"><!--[--><div class="navbar-item"><a href="/study/java/" class="" aria-label="Java"><!--[--><!--]--> Java <!--[--><!--]--></a></div><div class="navbar-item"><a href="/study/go/" class="" aria-label="Go"><!--[--><!--]--> Go <!--[--><!--]--></a></div><div class="navbar-item"><a href="/study/python/" class="" aria-label="Python"><!--[--><!--]--> Python <!--[--><!--]--></a></div><div class="navbar-item"><a href="/study/mw/" class="router-link-active" aria-label="中间件"><!--[--><!--]--> 中间件 <!--[--><!--]--></a></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading">Flink基本篇 <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#第一章-初识flink" class="router-link-active router-link-exact-active sidebar-item" aria-label="第一章 初识Flink"><!--[--><!--]--> 第一章 初识Flink <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#flink流处理简介" class="router-link-active router-link-exact-active sidebar-item" aria-label="Flink流处理简介"><!--[--><!--]--> Flink流处理简介 <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#flink的特点" class="router-link-active router-link-exact-active sidebar-item" aria-label="flink的特点"><!--[--><!--]--> flink的特点 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#flink是什么" class="router-link-active router-link-exact-active sidebar-item" aria-label="Flink是什么"><!--[--><!--]--> Flink是什么 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#为什么要用flink" class="router-link-active router-link-exact-active sidebar-item" aria-label="为什么要用Flink"><!--[--><!--]--> 为什么要用Flink <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#流处理的发展和演变" class="router-link-active router-link-exact-active sidebar-item" aria-label="流处理的发展和演变"><!--[--><!--]--> 流处理的发展和演变 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#flink的主要特点" class="router-link-active router-link-exact-active sidebar-item" aria-label="Flink的主要特点"><!--[--><!--]--> Flink的主要特点 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#分层api" class="router-link-active router-link-exact-active sidebar-item" aria-label="分层API"><!--[--><!--]--> 分层API <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#flink与spark的一些区别" class="router-link-active router-link-exact-active sidebar-item" aria-label="Flink与Spark的一些区别"><!--[--><!--]--> Flink与Spark的一些区别 <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#第二章-快速上手" class="router-link-active router-link-exact-active sidebar-item" aria-label="第二章 快速上手"><!--[--><!--]--> 第二章 快速上手 <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#环境准备" class="router-link-active router-link-exact-active sidebar-item" aria-label="环境准备"><!--[--><!--]--> 环境准备 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#批处理" class="router-link-active router-link-exact-active sidebar-item" aria-label="批处理"><!--[--><!--]--> 批处理 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#流处理" class="router-link-active router-link-exact-active sidebar-item" aria-label="流处理"><!--[--><!--]--> 流处理 <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#第三章-flink部署" class="router-link-active router-link-exact-active sidebar-item" aria-label="第三章 Flink部署"><!--[--><!--]--> 第三章 Flink部署 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/study/mw/Flink/Flink%E5%9F%BA%E6%9C%AC%E7%AF%87/flink%E5%9F%BA%E6%9C%AC%E7%AF%87.html#第四章-flink运行时架构" class="router-link-active router-link-exact-active sidebar-item" aria-label="第四章 Flink运行时架构"><!--[--><!--]--> 第四章 Flink运行时架构 <!--[--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><h1 id="flink基本篇" tabindex="-1"><a class="header-anchor" href="#flink基本篇" aria-hidden="true">#</a> Flink基本篇</h1><h2 id="第一章-初识flink" tabindex="-1"><a class="header-anchor" href="#第一章-初识flink" aria-hidden="true">#</a> 第一章 初识Flink</h2><h3 id="flink流处理简介" tabindex="-1"><a class="header-anchor" href="#flink流处理简介" aria-hidden="true">#</a> Flink流处理简介</h3><h4 id="flink的特点" tabindex="-1"><a class="header-anchor" href="#flink的特点" aria-hidden="true">#</a> flink的特点</h4><ul><li><p>低延迟</p></li><li><p>高吞吐</p></li><li><p>语义化窗口</p></li><li><p>高容错</p></li><li><p>易用的API</p></li></ul><h4 id="flink是什么" tabindex="-1"><a class="header-anchor" href="#flink是什么" aria-hidden="true">#</a> Flink是什么</h4><ol><li><p>Flink是一个大数据处理框架（处理引擎），Flink做的是流处理，Spark做的是批处理.</p></li><li><p>flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行<strong>状态</strong>计算</p><p>有界可以按时间划分有界，也可以按数据量划分有界。</p><p>flink是数据处理框架的代表</p><p>突出一个快速和灵巧</p></li><li><p>内存级别的响应速度，可扩展性很好。</p></li><li><p>flink框架处理流程</p><p><img src="/study/assets/image-20221116103533370.1e0f48ca.png" alt="image-20221116103533370"></p><p>flink要做的就是从外部把数据读取进来，然后做各种类型的处理。</p><p><strong>这个处理的过程是实时的</strong>，每来一个新的数据，都可以进行处理，并可以把结果返回给应用作为一个响应，也可以将处理结果写入事件日志等。</p><p>所以简单来看，这就像一个管道一样，pipeline，有一个数据源，数据源进来之后进行实时的处理，只要不断有数据进来，这些数据都能得到实时的处理。</p><p>左边数据进，右边数据出，从不同的数据存储介质里面读取数据，那么也可以将处理之后的数据写入不同的存储介质。</p><p>这就是flink的一个大概应用过程。</p><p>flink在多种场景都可以使用，只要数据源是实时的，或者业务需要对数据进行实时处理！</p></li><li><p>flink的应用场景：</p><ul><li>电商： <ul><li>实时报表</li><li>实时推荐</li><li>订单状态跟踪</li><li>信息推送</li></ul></li><li>物联网： <ul><li>实时数据采集</li><li>实时告警</li></ul></li><li>银行和金融业 <ul><li>实时结算</li><li>风险检测</li></ul></li></ul><p>实时数据处理在国内的场景太多了。比较典型的，比如一单实时的交易订单，完成之后，这就是实时数据，必须得到实时的处理，有实时的响应返回给应用，紧跟着有对应的消息下发给用户。</p><p>比如物流配送，是要实时地追踪物流订单的状态的。</p><p>如果数据量小，那么<strong>几台服务器部署后端服务</strong>，就可以搞定，但是海量的数据，就需要用上flink这个分布式<strong>实时计算框架</strong>了。</p></li></ol><h4 id="为什么要用flink" tabindex="-1"><a class="header-anchor" href="#为什么要用flink" aria-hidden="true">#</a> 为什么要用Flink</h4><ol><li><p>flink是流处理</p><p>真实的业务场景下，更多的是需要流式的处理（需要数据被实时地处理），数据都是像流一样一条条的，这样的场景多，但是数据一批一批的这样的场景也有。</p><p>批处理尽管<strong>实时性不太好</strong>，但是从系统设计和实际经验来看都是比较方便和高效的方式。</p><p>所以实时性，低延迟是批处理不具备的。</p></li><li><p>目标</p><ul><li>低延迟</li><li>高吞吐：也就是很快地处理海量数据。处理的数据量既大，处理数据又实时。</li><li>结果的准确性和容错性（如果发生故障，那么要能够恢复到数据之前的状态）</li></ul></li><li><p>传统数据处理架构</p><ul><li><p>事务处理</p><p>所谓计算层就是指的后台服务，这就是传统的web后端服务的架构，接收请求，处理请求，和数据库进行交互，响应给前端。</p><p>存储层也不完全是传统关系型数据库，NoSQL也是，比如MongoDB，REDIS内存级别的键值对数据库，Nebula Graph图数据库，ES、Solr这种文档型数据 库，他们所扮演的角色是一样的，就是数据存储层。数据存储层具有最大的一个特点就是数据具有持久性，那么要和数据库进行交互，当请求多，请求量大的时候，会存在响应慢的问题，除了Redis，因为Redis是内存级别的，但是Redis的成本很高。</p><p><img src="/study/assets/image-20221116111705471.cc500364.png" alt="image-20221116111705471"></p></li><li><p>分析处理</p><p>数据量可以非常大，但是是离线的。</p></li></ul><p>而我们现在的目标是低延迟高吞吐，又快数据量又大，不要离线的。既然要快，那么就要借鉴事务处理的架构，来一个就处理一下，如果说用事务处理的架构，关系型数据库变成了一个瓶颈，扩展起来之后速度变慢造价又高，那么现在一个基本的想法就是，直接把远程持久化存储变成一个本地状态，存在内存里面。</p><p><img src="/study/assets/image-20221116112947247.33282067.png" alt="image-20221116112947247"></p><p>基于这种想法，就有了有状态的流处理这种概念。</p><p>仍然是传统的架构，请求来了之后，计算，和存储层交互，但是存储层不使用持久化关系型数据库，而是改成一个本地状态，存储在内存中。和内存中的数据交互比和磁盘交互显然要快很多。</p><p>状态存储在内存中会有数据安全问题，所以flink会定期的将本地状态（内存中的状态）存盘，存进持久化数据库中去。---check point</p></li></ol><h4 id="流处理的发展和演变" tabindex="-1"><a class="header-anchor" href="#流处理的发展和演变" aria-hidden="true">#</a> 流处理的发展和演变</h4><ol><li><p>流处理的演变</p><ul><li><p>lambda架构</p><p>用两套系统，同时保证低延迟和结果准确</p><p>批处理器需要攒一批数据再处理，这就不够快，但是这能够保证数据的正确性。</p><p><img src="/study/assets/image-20221116113707728.358592ec.png" alt="image-20221116113707728"></p></li><li><p>新一代流处理器-Flink</p><p>用一套系统把lambda架构的两套功能全都搞定。</p><p>同时做到了低延迟和高吞吐。</p><p>对于Flink而言，它能够做到每秒钟处理百万级别的数据。</p><p>Flink能够保证结果准确性，Flink有事件时间的概念，这个事件时间就可以处理数据乱序。具体放在后面再讲。</p></li></ul></li><li><p>架构简图</p><ul><li><p>事件驱动型应用</p><p><img src="/study/assets/image-20221116115014606.fb2fc5b0.png" alt="image-20221116115014606"></p><p>数据源比较常见的是消息队列，所以比较常见的一个架构就是Flink直接去连接消息队列。</p><p>flink和kafka的连接是很常见的一种架构。</p><p>本地的状态就取代了原先的关系型数据库。</p></li><li><p>数据分析型应用</p><p><img src="/study/assets/image-20221116115412980.282b7519.png" alt="image-20221116115412980"></p><p>这就是一个实时的分析了。</p></li></ul></li></ol><h4 id="flink的主要特点" tabindex="-1"><a class="header-anchor" href="#flink的主要特点" aria-hidden="true">#</a> Flink的主要特点</h4><ul><li>高吞吐</li><li>低延迟</li><li>结果准确性</li><li>精确一次的状态一致性保证---如果发生故障，恢复到故障之前的状态，是完全一致的，就像没有发生故障一样</li><li>可以与众多常用存储系统连接</li><li>高可用，支持动态扩展</li></ul><h4 id="分层api" tabindex="-1"><a class="header-anchor" href="#分层api" aria-hidden="true">#</a> 分层API</h4><ol><li><p>整体来讲，Flink API分了四层</p><p>越顶层越抽象，表达含义越简明，使用越方便。</p><p>越底层越具体，表达能力越丰富，使用越灵活。</p><ul><li><p>SQL--最高层语言</p></li><li><p>Table API--声明式领域专用语言</p></li><li><p>DataStream/DataSet--核心API</p><p>在1.12版本之后，实现了统一，用DataStream API能做流处理和批处理。</p></li><li><p>有状态流处理--底层API</p></li></ul></li></ol><h3 id="flink与spark的一些区别" tabindex="-1"><a class="header-anchor" href="#flink与spark的一些区别" aria-hidden="true">#</a> Flink与Spark的一些区别</h3><p>数据处理架构</p><ol><li><p>flink认为批数据是特殊的流，是有界的数据流，这个边界在flink中叫做窗口。</p><p>spark认为把批数据切得足够小，就是流了。</p></li></ol><p>数据处理模型</p><ol><li>flink基本数据模型是数据流，以及事件（Event）序列。</li><li>spark采用的是RDD（弹性分布式数据集）模型，spark streaming的DStream实际上也是一组组小批数据RDD的集合。</li></ol><p>运行时架构</p><ol><li>spark是批计算，将DAG划分为<strong>不同的stage</strong>，一个完成后才可以做下一个。</li><li>flink是标准的流执行模式，一个事件（数据）在一个节点处理完后可以直接发往下一个节点进行处理，不用等其他事件或数据，就只跟当前数据和处理有关。</li></ol><h2 id="第二章-快速上手" tabindex="-1"><a class="header-anchor" href="#第二章-快速上手" aria-hidden="true">#</a> 第二章 快速上手</h2><h3 id="环境准备" tabindex="-1"><a class="header-anchor" href="#环境准备" aria-hidden="true">#</a> 环境准备</h3><ol><li><p>Flink底层是用Java编写的，并为开发人员提供了完整的Java和Scala API。</p></li><li><p>创建Maven项目</p></li><li><p>引入依赖</p><ul><li><p>properties</p><div class="language-xml ext-xml"><pre class="language-xml"><code>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>properties</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>project.build.sourceEncoding</span><span class="token punctuation">&gt;</span></span>UTF-8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>project.build.sourceEncoding</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>maven.compiler.source</span><span class="token punctuation">&gt;</span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>maven.compiler.source</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>maven.compiler.target</span><span class="token punctuation">&gt;</span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>maven.compiler.target</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>flink.version</span><span class="token punctuation">&gt;</span></span>1.13.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>flink.version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>java.version</span><span class="token punctuation">&gt;</span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>java.version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scala.binary.version</span><span class="token punctuation">&gt;</span></span>2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scala.binary.version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>slf4j.version</span><span class="token punctuation">&gt;</span></span>1.7.30<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>slf4j.version</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>properties</span><span class="token punctuation">&gt;</span></span>
</code></pre></div></li><li><p>flink相关依赖</p><div class="language-xml ext-xml"><pre class="language-xml"><code>    <span class="token comment">&lt;!--flink相关依赖 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${flink.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-streaming-java_${scala.binary.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${flink.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-clients_${scala.binary.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${flink.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div></li><li><p>日志管理依赖</p><div class="language-xml ext-xml"><pre class="language-xml"><code>    <span class="token comment">&lt;!--日志依赖 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.slf4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>slf4j-api<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${slf4j.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.slf4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>slf4j-log4j12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${slf4j.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.logging.log4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>log4j-to-slf4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.14.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div></li></ul><p>在properties中，定义了scala.binary.version，这指代的是所依赖的Scala版本。这有一点奇怪：Flink底层是Java，而且我们也只用JavaAPI，为什么还会依赖Scala呢？这是因为Flink的架构中使用了Akka来实现底层的分布式通信，而Akka是用Scala开发的。</p></li></ol><h3 id="批处理" tabindex="-1"><a class="header-anchor" href="#批处理" aria-hidden="true">#</a> 批处理</h3><ol><li><div class="language-java ext-java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">BatchWordCount</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">//1. 创建执行环境，flink的执行，是需要有一个复杂的集群，配合起来去做工作的，所以首先要创建执行环境</span>
        <span class="token class-name">ExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">ExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//2. 从文件中读取数据，得到了数据源</span>
        <span class="token class-name">DataSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> dataSource <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span><span class="token string">&quot;input/words.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//3. 将每行数据进行分词，转换成二元组类型,map是一个通用的转换方法</span>
        <span class="token class-name">FlatMapOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> wordTuple <span class="token operator">=</span> dataSource<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">String</span> line<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> out<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> <span class="token punctuation">{</span>
            <span class="token comment">// 收集器Collector也需要泛型，转换输出需要得到的类型是什么，Collector的泛型就写什么类型</span>
            <span class="token comment">// 在这里我们需要得到二元组，即每个单词的频次，那么这个泛型这里就需要写二元组</span>
            <span class="token comment">// 对于Scala来说，本身有元组类型，但是java没有，但是Flink定义了元组类型</span>

            <span class="token comment">// 1.将一行文本进行拆分</span>
            <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 2. 将每个单词转换成二元组输出</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> word <span class="token operator">:</span> words<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">1L</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">returns</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span><span class="token function">TUPLE</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span>STRING<span class="token punctuation">,</span> <span class="token class-name">Types</span><span class="token punctuation">.</span>LONG<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//4. 按照word进行分组,传入的是Tuple的索引位置,给0表示以索引为0的位置的元素即word来作为分组的key</span>
        <span class="token class-name">UnsortedGrouping</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> group <span class="token operator">=</span> wordTuple<span class="token punctuation">.</span><span class="token function">groupBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//5. 分组之后最终是要做统计的</span>
        <span class="token comment">// 分组内进行聚合，叠加</span>
        <span class="token comment">// 指定索引为1的位置的元素做求和的操作</span>
        <span class="token class-name">AggregateOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> sum <span class="token operator">=</span> group<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">try</span> <span class="token punctuation">{</span>
            sum<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">RuntimeException</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>所有的转换操作都是基于DataSet在转换，我们把以上这些调用的API叫做DataSet API，也就是Flink的核心API。</p><p>但是从1.12开始，统一使用DataStream API就可以同时实现批处理和流处理。</p></li></ol><h3 id="流处理" tabindex="-1"><a class="header-anchor" href="#流处理" aria-hidden="true">#</a> 流处理</h3><ol><li><p>用DataSet API可以很容易地实现批处理，与之对应，流处理当然可以用DataStream API来实现，对于Flink而言，流才是整个底层的核心逻辑，所以流批统一之后的DataStream API更加强大，可以直接处理批处理和流处理的所有场景。</p></li><li><p>在Flink的视角中，一切数据都可以认为是流，一切数据处理都可以认为是流处理。流数据是无界流，而<strong>批数据是有界流</strong>。</p></li><li><div class="language-java ext-java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">BoundedStreamWordCount</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">//1. 创建流处理的执行环境</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//2. 读取文件，得到的source，继承自DataStream，所以以下用到的这一套API，叫做DataStream API</span>
        <span class="token class-name">DataStreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> source <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">readTextFile</span><span class="token punctuation">(</span><span class="token string">&quot;input/words.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//3. 转换计算</span>
        <span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> wordTuple <span class="token operator">=</span> source<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">String</span> line<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> out<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> <span class="token punctuation">{</span>
            <span class="token comment">// 1.将一行文本进行拆分</span>
            <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 2. 将每个单词转换成二元组输出</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> word <span class="token operator">:</span> words<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">1L</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">returns</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span><span class="token function">TUPLE</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span>STRING<span class="token punctuation">,</span> <span class="token class-name">Types</span><span class="token punctuation">.</span>LONG<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//4. 按照word进行分组,传入的是Tuple的索引位置,给0表示以索引为0的位置的元素即word来作为分组的key</span>
        <span class="token class-name">KeyedStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> tuple2StringKeyedStream <span class="token operator">=</span> wordTuple<span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>data <span class="token operator">-&gt;</span> data<span class="token punctuation">.</span>f0<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//5. 分组之后最终是要做统计的</span>
        <span class="token comment">// 分组内进行聚合，叠加</span>
        <span class="token comment">// 指定索引为1的位置的元素做求和的操作</span>
        <span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> sum <span class="token operator">=</span> tuple2StringKeyedStream<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 6.打印</span>
        <span class="token comment">// 执行以下这一步是打印不出结果的，是因为这是流处理模式，我们只是当前读取了一个有边界的文件，但是实际上工作模式是流处理，会认为数据是无界的，源源不断会到来的</span>
        sum<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//7. 启动执行，每来一次数据去执行一次整个的流程，所以会有最后一步执行。</span>
        <span class="token comment">// 把有边界的数据也当作流数据，所以这个地方还没有结束，因为流处理模式认为数据会源源不断到来</span>
        <span class="token comment">// 如果真正流数据来了之后，这个地方还没完呢，还要继续等待数据</span>
        <span class="token keyword">try</span> <span class="token punctuation">{</span>
            env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">RuntimeException</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>结果</p><div class="language-text ext-text"><pre class="language-text"><code>7&gt; (flink,1)
5&gt; (world,1)
3&gt; (hello,1)
3&gt; (hello,2)
3&gt; (hello,3)
2&gt; (java,1)
</code></pre></div><p><strong>前面的这个数字就代表了当前是哪个子任务，子任务是按并行度划分的。</strong></p><p>flink是分布式流处理引擎，如果在本地启动，会在本地启动多线程模拟分布式环境</p><p>flink管最小的资源单位叫任务槽。</p><p>并行度就是指当前这个任务通过多线程并行执行，多线程的个数。如果没有设置并行度，那么默认就是当前机器的CPU核心数量。</p></li></ol><h2 id="第三章-flink部署" tabindex="-1"><a class="header-anchor" href="#第三章-flink部署" aria-hidden="true">#</a> 第三章 Flink部署</h2><h2 id="第四章-flink运行时架构" tabindex="-1"><a class="header-anchor" href="#第四章-flink运行时架构" aria-hidden="true">#</a> 第四章 Flink运行时架构</h2><!--]--></div><footer class="page-meta"><!----><div class="meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: 64005626+shaileneF@users.noreply.github.com">shailene</span><!----><!--]--><!--]--></span></div></footer><!----><!--[--><!--]--></main><!--]--></div><!----><!--]--></div>
    <script type="module" src="/study/assets/app.5448d7f4.js" defer></script>
  </body>
</html>
